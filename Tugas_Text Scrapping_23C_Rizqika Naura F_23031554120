import requests
from bs4 import BeautifulSoup
import csv

page = requests.get('https://kitalulus.com/lowongan')
bs = BeautifulSoup(page.text, 'html.parser')

print(bs.title.string)

lowongan = bs.find_all('h3', class_='TextStyled__H3-sc-18vo2dc-3')
print("\nLowongan Pekerjaan:")
lowongan_list = [link.text for link in lowongan]
for a in lowongan_list:
    print(a)

perusahaan = bs.find_all('p', class_='TextStyled__Text-sc-18vo2dc-0')
print("\nNama Perusahaan:")
perusahaan_list = [link.text.replace("Dipromosikan", "").strip() for link in perusahaan]
for z in perusahaan_list:
    print(z)

lokasi_dll = bs.find_all('p', class_='CardRectangleStyled__Text-sc-1lom4v1-8 drzZmb')
print("\nLokasi atau Detail Lainnya:")
lokasi_list = [n.text for n in lokasi_dll]
for n in lokasi_list:
    print(n)

links = bs.find_all('a')
print("\nTautan:")
tautan_list = [link.get('href') for link in links if link.get('href')]
for href in tautan_list:
    print(href)

with open('hasil_scraping_kitalulus.csv', mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)

    writer.writerow(['Lowongan Pekerjaan', 'Nama Perusahaan', 'Lokasi atau Lainnya', 'Tautan'])

    for i in range(min(len(lowongan_list), len(perusahaan_list), len(lokasi_list))):
        writer.writerow([lowongan_list[i], perusahaan_list[i], lokasi_list[i], tautan_list[i] if i < len(tautan_list) else ''])

print("Hasil scraping telah disimpan ke 'hasil_scraping_kitalulus.csv'")
